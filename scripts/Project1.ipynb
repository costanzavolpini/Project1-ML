{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import *\n",
    "from execute_code import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA LOADED!\n",
      "TEST DATA LOADED!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=False)\n",
    "print(\"TRAIN DATA LOADED!\")\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)\n",
    "print(\"TEST DATA LOADED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.342668, 0.657332)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == 1).mean(), (y == -1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.657332"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == -1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA LOADED!\n"
     ]
    }
   ],
   "source": [
    "y_sub, tx_sub, ids_sub = load_csv_data(\"datas/train.csv\", sub_sample=True)\n",
    "print(\"TRAIN DATA LOADED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3286, 0.6714)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_sub == 1).mean(), (y_sub == -1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean, median  or normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with mean for each feature\n",
    "# # train set\n",
    "\n",
    "# means = find_mean(tx)\n",
    "# tx_replaced_by_mean = replace_missing_values(tx, means)\n",
    "\n",
    "# # test set\n",
    "# means_test = find_mean(tx_test)\n",
    "# tx_replaced_by_mean_test = replace_missing_values(tx_test, means_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for each feature\n",
    "# # train set\n",
    "# medians = find_median(tx)\n",
    "# tx_replaced_by_median = replace_missing_values(tx, medians)\n",
    "\n",
    "# # test set\n",
    "# medians_test = find_median(tx_test)\n",
    "# tx_replaced_by_median_test = replace_missing_values(tx_test, medians_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with 0 and before that normalize all values without considering missing values\n",
    "# std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "# tx_std_data_replaced_by_0 = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_jet_0, features_jet_1, features_jet_2, features_jet_3, y_jet_0, y_jet_1, y_jet_2, y_jet_3, ids_jet_0, ids_jet_1, ids_jet_2, ids_jet_3 = generate_4_sets_looking_on_jetnum(tx, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate to find which columns to drop\n",
    "# columns_to_remove_0 = columns_contains_just_missing_values(features_jet_0[0])\n",
    "# columns_to_remove_1 = columns_contains_just_missing_values(features_jet_1[0])\n",
    "# columns_to_remove_2 = columns_contains_just_missing_values(features_jet_2[0])\n",
    "# columns_to_remove_3 = columns_contains_just_missing_values(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28. And also we will drop feature 22 since it is the one of jet_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop feature 22 since it is the one of jet_num and it will contains the same value.\n",
    "# columns_to_remove_0.append(22)\n",
    "# columns_to_remove_1.append(22)\n",
    "# columns_to_remove_2.append(22)\n",
    "# columns_to_remove_3.append(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for constant values, if I feature contains all the same values it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove_0_b = columns_contains_same_value(features_jet_0[0])\n",
    "# columns_to_remove_1_b = columns_contains_same_value(features_jet_1[0])\n",
    "# columns_to_remove_2_b = columns_contains_same_value(features_jet_2[0])\n",
    "# columns_to_remove_3_b = columns_contains_same_value(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that as predicted we should removed feature 22. We have found also feature 29 to remove from column 0.\n",
    "Since before we have dropped columns full of -999 (same value) we can just remove these features from each set.\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> [22]\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove columns from subset    \n",
    "# features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0_b, axis=1)\n",
    "# features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1_b, axis=1)\n",
    "# features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2_b, axis=1)\n",
    "# features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "# tx_dropped_columns = np.delete(tx, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 19\n",
    "# degree = 7\n",
    "# k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "# k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.804520 - Accuracy test: 0.799740 - Loss: 0.575760\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.800310 - Accuracy test: 0.802020 - Loss: 0.585639\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.806710 - Accuracy test: 0.808080 - Loss: 0.572250\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.804575 - Accuracy test: 0.800720 - Loss: 0.576161\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.803565 - Accuracy test: 0.804200 - Loss: 0.577485\n",
      "\n",
      "Accuracy test, mean: 0.802952, min value: 0.799740, max value: 0.808080 \n",
      "\n",
      "Accuracy train, mean: 0.803936, min value: 0.800310, max value: 0.806710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "    \n",
    "# # Just for study the behaviour\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.805525 - Accuracy test: 0.801640 - Loss: 0.573839\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.804210 - Accuracy test: 0.807480 - Loss: 0.576331\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.808065 - Accuracy test: 0.809400 - Loss: 0.569957\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.805485 - Accuracy test: 0.801400 - Loss: 0.574242\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.804755 - Accuracy test: 0.805380 - Loss: 0.575564\n",
      "\n",
      "Accuracy test, mean: 0.805060, min value: 0.801400, max value: 0.809400 \n",
      "\n",
      "Accuracy train, mean: 0.805608, min value: 0.804210, max value: 0.808065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study the behaviour    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by 0 after having normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_std_data_replaced_by_0, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cross validation, division by jet_num with different ML implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test jet_num_0 dataset with:\n",
    "- **Least squares regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 <br/>\n",
    "    Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
    "- **Ridge regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.503224, min value: 0.476574, max value: 0.531486 <br/>\n",
    "    Accuracy train, mean: 0.503237, min value: 0.473804, max value: 0.538035 \n",
    "- **Linear regression using gradient descent**: <br/>\n",
    "- **Linear regression using stochastic gradient descent**:\n",
    "- **Logistic regression using gradient descent or SGD**:\n",
    "- **Regularized logistic regression using gradient descent or SGD**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.511335 - Accuracy test: 0.513854 - Loss: 417040.188757\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.773929 - Accuracy test: 0.795970 - Loss: 0.739157\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.529597 - Accuracy test: 0.511335 - Loss: 95905.419265\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.534635 - Accuracy test: 0.549118 - Loss: 1306.744284\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.580605 - Accuracy test: 0.546599 - Loss: 21577866.290756\n",
      "\n",
      "Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 \n",
      "\n",
      "Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    }
   ],
   "source": [
    "# # accuracy_train = []\n",
    "# # accuracy_test = []\n",
    "# # losses = []\n",
    "# # weights = []\n",
    "\n",
    "# # for k in range(k_fold):\n",
    "# #     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "# #     accuracy_train.append(single_accuracy_train)\n",
    "# #     accuracy_test.append(single_accuracy_test)\n",
    "# #     losses.append(loss)\n",
    "# #     weights.append(w)\n",
    "\n",
    "    \n",
    "# # n = len(accuracy_train)\n",
    "# # for i in range(n):\n",
    "# #     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# # mean_accuracy_test = np.mean(accuracy_test)\n",
    "# # min_accuracy_test = np.min(accuracy_test)\n",
    "# # max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# # mean_accuracy_train = np.mean(accuracy_train)\n",
    "# # min_accuracy_train = np.min(accuracy_train)\n",
    "# # max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# # print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# # print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "# #LEAST SQUARE\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RIDGE REGRESSION\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/helpers.py:5: RuntimeWarning: overflow encountered in square\n",
      "  return 1/(len(y)) * np.sum(e**2)\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Accuracy test, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n",
      "Accuracy train, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # GRADIENT DESCEND \n",
    "# # HEREEEE! NOT WORK!\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "# gamma = 0.01\n",
    "# max_iterations = 500\n",
    "\n",
    "# # CHECK SHAPES!!!!!!!!!!!!!!!!!!!!! and correct!\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# initial_w = np.zeros(features_dropped_0.shape[1])\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, gradient_descent, initial_w=initial_w, max_iters=max_iterations, gamma=gamma)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28075458,  0.03965436,  0.40651625, ...,  0.61755292,\n",
       "        -1.30266251,  0.39818214],\n",
       "       [ 1.63061547,  0.63344061,  1.05925506, ...,  0.        ,\n",
       "         0.        , -0.23179611],\n",
       "       [-0.51771811, -0.64151886, -0.37784339, ...,  0.        ,\n",
       "         0.        , -0.10829837],\n",
       "       ...,\n",
       "       [ 0.34569571, -1.22366112,  0.43998942, ...,  0.        ,\n",
       "         0.        ,  0.23416077],\n",
       "       [-0.72942585, -0.11217409, -0.50441304, ...,  0.        ,\n",
       "         0.        , -0.41106251],\n",
       "       [ 0.13958259, -1.31829705, -0.3187276 , ...,  0.        ,\n",
       "         0.        , -0.22539659]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test_predicted = []\n",
    "# test_poly = build_poly(tx_median_test, degree)\n",
    "# y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "# create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 397), (1985,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build_k_indices(y_0, 5, 19).shape, y_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test my new file!!!!!!!!!!! DA QUI:\n",
    "y_test = np.zeros(tx_test.shape[0])\n",
    "# tx_med = replace_set_median(tx)\n",
    "tx_out = tx\n",
    "# tx_out = outlier_removal(tx_med, 95, 1, per_top = True, per_bot = True)\n",
    "tx_0, tx_1, tx_2, tx_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 = divide_dataset_looking_jetnum_and_remove_features(y, tx_out, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_0 = tx_0.copy()\n",
    "tx_1 = tx_1.copy()\n",
    "tx_2 = tx_2.copy()\n",
    "tx_3 = tx_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-e535d0a1faa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_all_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected method \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"with accuracy %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/execute_code.py\u001b[0m in \u001b[0;36mexecute_all_methods\u001b[0;34m(y, tx, ids, cross_validation_flag, degree, **args)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mw_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0maccuracy3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_one_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3. GRADIENT DESCENT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares_GD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_w\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_iters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy3\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mmax_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/execute_code.py\u001b[0m in \u001b[0;36mexecute_one_method\u001b[0;34m(y, tx, ids, method_name, cross_validation_flag, degree, m, **args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0maccuracy_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k, degree, m, **args)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# methods used to calculate weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# predict the y given weight and data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/implementations.py\u001b[0m in \u001b[0;36mleast_squares_GD\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# compute loss, gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# gradient w by descent update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/helpers.py\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"Compute the gradient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc0, m0, w0 = execute_all_methods(y_0, tx_0, ids_0, True, 8, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", m0)\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  Logistic\n",
      "with accuracy 0.728636\n"
     ]
    }
   ],
   "source": [
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"logistic\", True, 10, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", \"Logistic\")\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  Logistic\n",
      "with accuracy 0.708568\n"
     ]
    }
   ],
   "source": [
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"logistic\", True, 8, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", \"Logistic\")\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  Ridge\n",
      "with accuracy 0.760134\n"
     ]
    }
   ],
   "source": [
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"ridge\", True, 7, ridge_regression, lambda_=0.01)\n",
    "print(\"Selected method \", \"Ridge\")\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  Ridge\n",
      "with accuracy 0.746071\n"
     ]
    }
   ],
   "source": [
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"ridge\", True, 6, ridge_regression, lambda_=0.1)\n",
    "print(\"Selected method \", \"Ridge\")\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with accuracy 0.684826\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.744156\n"
     ]
    }
   ],
   "source": [
    "acc1, m1, w1 = execute_all_methods(y_1, tx_1, ids_1, True, 6, lambda_=0.0001, initial_w=None, max_iters=800, gamma=1e-3)\n",
    "print(\"Selected method \", m1)\n",
    "print(\"with accuracy %f\" %(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.767308\n"
     ]
    }
   ],
   "source": [
    "acc2, m2, w2 = execute_all_methods(y_2, tx_2, ids_2, True, 5, lambda_=0.0001, initial_w=None, max_iters=3000, gamma=1e-3)\n",
    "print(\"Selected method \", m2)\n",
    "print(\"with accuracy %f\" %(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.709302\n"
     ]
    }
   ],
   "source": [
    "acc3, m3, w3 = execute_all_methods(y_3, tx_3, ids_3, True, 10, lambda_=0.0001, initial_w=None, max_iters=800, gamma=1e-2)\n",
    "print(\"Selected method \", m3)\n",
    "print(\"with accuracy %f\" %(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_0_t, tx_1_t, tx_2_t, tx_3_t, _, _, _, _, ids_0_t, ids_1_t, ids_2_t, ids_3_t = divide_dataset_looking_jetnum_and_remove_features(y_test, tx_test, ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.50000e+05 -1.00000e+00]\n",
      " [ 3.50002e+05  1.00000e+00]\n",
      " [ 3.50003e+05  1.00000e+00]\n",
      " ...\n",
      " [ 9.18232e+05 -1.00000e+00]\n",
      " [ 9.18235e+05  1.00000e+00]\n",
      " [ 9.18237e+05 -1.00000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., ...,  1.,  1., -1.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_submission(tx_0_t, tx_1_t, tx_2_t, tx_3_t, ids_0_t, ids_1_t, ids_2_t, ids_3_t, w0, w1, w2, w3, \"submission-28-10-to-submit\", 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 204, 204, 127)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w1), len(w2), len(w3), len(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final = np.concatenate((w0, w1, w2, w3))\n",
    "ids_final = np.concatenate((ids_0, ids_1, ids_2, ids_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0030e+05 -1.0000e+00]\n",
      " [ 1.0035e+05 -1.0000e+00]\n",
      " [ 1.0050e+05 -1.0000e+00]\n",
      " ...\n",
      " [ 3.4945e+05 -1.0000e+00]\n",
      " [ 3.4955e+05  1.0000e+00]\n",
      " [ 3.4970e+05 -1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "preddd = generate_submission(tx_0, tx_1, tx_2, tx_3, ids_0, ids_1, ids_2, ids_3, w0, w1, w2, w3, \"submission-28-10-to-submit\", 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preddd == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1985,37) and (127,) not aligned: 37 (dim 1) != 127 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-3aa7dbe4b7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_poly0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_poly0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_set_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_poly0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_test_predicted0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_poly0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_predicted0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/proj1_helpers.py\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1985,37) and (127,) not aligned: 37 (dim 1) != 127 (dim 0)"
     ]
    }
   ],
   "source": [
    "    y_test_predicted0 = []\n",
    "    test_poly0 = build_poly(tx_0, degree)\n",
    "    test_poly0 = replace_set_normalize(test_poly0)\n",
    "    y_test_predicted0 = predict_labels(w0, test_poly0)\n",
    "np.sum(y_test_predicted0 == y_0)/len(y_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766233766233767"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted1 = []\n",
    "    test_poly1 = build_poly(tx_1, degree)\n",
    "    test_poly1 = replace_set_normalize(test_poly1)\n",
    "    y_test_predicted1 = predict_labels(w1, test_poly1)\n",
    "np.sum(y_test_predicted1 == y_1)/len(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293384467881112"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted2 = []\n",
    "    test_poly2 = build_poly(tx_2, degree)\n",
    "    test_poly2 = replace_set_normalize(test_poly2)\n",
    "    y_test_predicted2 = predict_labels(w2, test_poly2)\n",
    "np.sum(y_test_predicted2 == y_2)/len(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893518518518519"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted3 = []\n",
    "    test_poly3 = build_poly(tx_3, degree)\n",
    "    test_poly3 = replace_set_normalize(test_poly3)\n",
    "    y_test_predicted3 = predict_labels(w3, test_poly3)\n",
    "np.sum(y_test_predicted3 == y_3)/len(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with accuracy 0.684826\n",
      "with accuracy 0.675522\n",
      "with accuracy 0.735762\n",
      "with accuracy 0.586282\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (99913,145) and (37,) not aligned: 145 (dim 1) != 37 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-21b97400e63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# 5. Generate submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfinal_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"submission-28-10-to-submit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_prediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/execute_code.py\u001b[0m in \u001b[0;36mgenerate_submission\u001b[0;34m(tx0, tx1, tx2, tx3, ids0, ids1, ids2, ids3, w0, w1, w2, w3, name, degrees)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mtest_poly0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mtest_poly0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_set_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_poly0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0my_test_predicted0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_poly0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0my_test_predicted1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/proj1_helpers.py\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (99913,145) and (37,) not aligned: 145 (dim 1) != 37 (dim 0)"
     ]
    }
   ],
   "source": [
    "# 1. Load datasets\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=False)\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)\n",
    "\n",
    "# 2. Divide the train dataset looking on jet_num feature (column 22 of tx)\n",
    "tx_0, tx_1, tx_2, tx_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 = divide_dataset_looking_jetnum_and_remove_features(y, tx, ids)\n",
    "\n",
    "# 3. Execute all methods on all subsets\n",
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"logistic\", True, 2, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "# print(\"Selected method \", m0)\n",
    "print(\"with accuracy %f\" %(acc0))\n",
    "\n",
    "acc1, w1 = execute_one_method(y_1, tx_1, ids_1, \"logistic\", True, 2, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "# print(\"Selected method \", m1)\n",
    "print(\"with accuracy %f\" %(acc1))\n",
    "\n",
    "acc2, w2 = execute_one_method(y_2, tx_2, ids_2, \"logistic\", True, 2, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "# print(\"Selected method \", m2)\n",
    "print(\"with accuracy %f\" %(acc2))\n",
    "\n",
    "acc3, w3 = execute_one_method(y_3, tx_3, ids_3, \"logistic\", True, 2, logistic_regression, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "# print(\"Selected method \", m3)\n",
    "print(\"with accuracy %f\" %(acc3))\n",
    "\n",
    "# 4. Divide the test dataset looking on jet_num feature (column 22 of tx)\n",
    "tx_0_t, tx_1_t, tx_2_t, tx_3_t, _, _, _, _, ids_0_t, ids_1_t, ids_2_t, ids_3_t = divide_dataset_looking_jetnum_and_remove_features(no_y, tx_test, ids_test)\n",
    "\n",
    "# 5. Generate submission\n",
    "final_prediction = generate_submission(tx_0, tx_1, tx_2, tx_3, ids_0, ids_1, ids_2, ids_3, w0, w1, w2, w3, \"submission-28-10-to-submit\", [8, 6, 2, 10])\n",
    "\n",
    "print(np.sum(final_prediction == y)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Imports\n",
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import *\n",
    "from execute_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load datasets\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=False)\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_k_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba31c16bcd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 3. Execute all methods on all subsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0macc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_one_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected method \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ridge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"with accuracy %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/execute_code.py\u001b[0m in \u001b[0;36mexecute_one_method\u001b[0;34m(y, tx, ids, method_name, cross_validation_flag, degree, m, **args)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0maccuracy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mk_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_k_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_k_indices' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Divide the train dataset looking on jet_num feature (column 22 of tx)\n",
    "tx_0, tx_1, tx_2, tx_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 = divide_dataset_looking_jetnum_and_remove_features(y, tx, ids)\n",
    "\n",
    "\n",
    "# 3. Execute all methods on all subsets\n",
    "acc0, w0 = execute_one_method(y_0, tx_0, ids_0, \"logistic\", True, 8, logistic_regression, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", \"Ridge\")\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
