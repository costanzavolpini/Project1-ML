{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import generate_4_sets_looking_on_jetnum, columns_contains_just_missing_values, columns_contains_same_value\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATAS LOADED!\n",
      "TEST DATAS LOADED!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=True)\n",
    "print(\"TRAIN DATAS LOADED!\")\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=True)\n",
    "print(\"TEST DATAS LOADED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean, median  or normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with mean for each feature\n",
    "# train set\n",
    "means = find_mean(tx)\n",
    "tx_replaced_by_mean = replace_missing_values(tx, means)\n",
    "\n",
    "# test set\n",
    "means_test = find_mean(tx_test)\n",
    "tx_replaced_by_mean_test = replace_missing_values(tx_test, means_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for each feature\n",
    "# train set\n",
    "medians = find_median(tx)\n",
    "tx_replaced_by_median = replace_missing_values(tx, medians)\n",
    "\n",
    "# test set\n",
    "medians_test = find_median(tx_test)\n",
    "tx_replaced_by_median_test = replace_missing_values(tx_test, medians_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 0 and before that normalize all values without considering missing values\n",
    "std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "tx_std_data_replaced_by_0 = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_jet_0, features_jet_1, features_jet_2, features_jet_3, y_jet_0, y_jet_1, y_jet_2, y_jet_3, ids_jet_0, ids_jet_1, ids_jet_2, ids_jet_3 = generate_4_sets_looking_on_jetnum(tx, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate to find which columns to drop\n",
    "columns_to_remove_0 = columns_contains_just_missing_values(features_jet_0[0])\n",
    "columns_to_remove_1 = columns_contains_just_missing_values(features_jet_1[0])\n",
    "columns_to_remove_2 = columns_contains_just_missing_values(features_jet_2[0])\n",
    "columns_to_remove_3 = columns_contains_just_missing_values(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28. And also we will drop feature 22 since it is the one of jet_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature 22 since it is the one of jet_num and it will contains the same value.\n",
    "columns_to_remove_0.append(22)\n",
    "columns_to_remove_1.append(22)\n",
    "columns_to_remove_2.append(22)\n",
    "columns_to_remove_3.append(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for constant values, if I feature contains all the same values it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove_0_b = columns_contains_same_value(features_jet_0[0])\n",
    "columns_to_remove_1_b = columns_contains_same_value(features_jet_1[0])\n",
    "columns_to_remove_2_b = columns_contains_same_value(features_jet_2[0])\n",
    "columns_to_remove_3_b = columns_contains_same_value(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that as predicted we should removed feature 22. We have found also feature 29 to remove from column 0.\n",
    "Since before we have dropped columns full of -999 (same value) we can just remove these features from each set.\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> [22]\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns from subset    \n",
    "features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0_b, axis=1)\n",
    "features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1_b, axis=1)\n",
    "features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2_b, axis=1)\n",
    "features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "tx_dropped_columns = np.delete(tx, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 19\n",
    "degree = 7\n",
    "k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.804520 - Accuracy test: 0.799740 - Loss: 0.575760\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.800310 - Accuracy test: 0.802020 - Loss: 0.585639\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.806710 - Accuracy test: 0.808080 - Loss: 0.572250\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.804575 - Accuracy test: 0.800720 - Loss: 0.576161\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.803565 - Accuracy test: 0.804200 - Loss: 0.577485\n",
      "\n",
      "Accuracy test, mean: 0.802952, min value: 0.799740, max value: 0.808080 \n",
      "\n",
      "Accuracy train, mean: 0.803936, min value: 0.800310, max value: 0.806710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Just for study the behaviour\n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.805525 - Accuracy test: 0.801640 - Loss: 0.573839\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.804210 - Accuracy test: 0.807480 - Loss: 0.576331\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.808065 - Accuracy test: 0.809400 - Loss: 0.569957\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.805485 - Accuracy test: 0.801400 - Loss: 0.574242\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.804755 - Accuracy test: 0.805380 - Loss: 0.575564\n",
      "\n",
      "Accuracy test, mean: 0.805060, min value: 0.801400, max value: 0.809400 \n",
      "\n",
      "Accuracy train, mean: 0.805608, min value: 0.804210, max value: 0.808065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "# Just for study the behaviour    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by 0 after having normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_std_data_replaced_by_0, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "# Just for study    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "\n",
    "# Just for study    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cross validation, division by jet_num with different ML implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test jet_num_0 dataset with:\n",
    "- **Least squares regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 <br/>\n",
    "    Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
    "- **Ridge regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.503224, min value: 0.476574, max value: 0.531486 <br/>\n",
    "    Accuracy train, mean: 0.503237, min value: 0.473804, max value: 0.538035 \n",
    "- **Linear regression using gradient descent**: <br/>\n",
    "- **Linear regression using stochastic gradient descent**:\n",
    "- **Logistic regression using gradient descent or SGD**:\n",
    "- **Regularized logistic regression using gradient descent or SGD**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.511335 - Accuracy test: 0.513854 - Loss: 417040.188757\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.773929 - Accuracy test: 0.795970 - Loss: 0.739157\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.529597 - Accuracy test: 0.511335 - Loss: 95905.419265\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.534635 - Accuracy test: 0.549118 - Loss: 1306.744284\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.580605 - Accuracy test: 0.546599 - Loss: 21577866.290756\n",
      "\n",
      "Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 \n",
      "\n",
      "Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    }
   ],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "#LEAST SQUARE\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.506423 - Accuracy test: 0.504786 - Loss: 249676896.542092\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.473804 - Accuracy test: 0.481612 - Loss: 268042139218.589996\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.499748 - Accuracy test: 0.504786 - Loss: 373696623.679606\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.495340 - Accuracy test: 0.510327 - Loss: 839357806.641875\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.518388 - Accuracy test: 0.503778 - Loss: 6229035830927.332031\n",
      "\n",
      "Iteration: 5) Accuracy train: 0.523804 - Accuracy test: 0.501763 - Loss: 612586082.687964\n",
      "\n",
      "Iteration: 6) Accuracy train: 0.525819 - Accuracy test: 0.499748 - Loss: 189221295.862311\n",
      "\n",
      "Iteration: 7) Accuracy train: 0.522796 - Accuracy test: 0.530982 - Loss: 12777318717.023151\n",
      "\n",
      "Iteration: 8) Accuracy train: 0.480227 - Accuracy test: 0.499244 - Loss: 14944530495.687542\n",
      "\n",
      "Iteration: 9) Accuracy train: 0.483249 - Accuracy test: 0.494710 - Loss: 6632744315.562798\n",
      "\n",
      "Iteration: 10) Accuracy train: 0.511461 - Accuracy test: 0.496222 - Loss: 2910129370.889274\n",
      "\n",
      "Iteration: 11) Accuracy train: 0.538035 - Accuracy test: 0.506297 - Loss: 332034783206.679077\n",
      "\n",
      "Iteration: 12) Accuracy train: 0.485013 - Accuracy test: 0.480101 - Loss: 18902672265.392788\n",
      "\n",
      "Iteration: 13) Accuracy train: 0.514232 - Accuracy test: 0.520403 - Loss: 33514586162.640442\n",
      "\n",
      "Iteration: 14) Accuracy train: 0.494584 - Accuracy test: 0.476574 - Loss: 55375130067.274658\n",
      "\n",
      "Iteration: 15) Accuracy train: 0.505542 - Accuracy test: 0.498237 - Loss: 8919798608.979488\n",
      "\n",
      "Iteration: 16) Accuracy train: 0.521285 - Accuracy test: 0.506297 - Loss: 33025304431.090424\n",
      "\n",
      "Iteration: 17) Accuracy train: 0.483249 - Accuracy test: 0.500756 - Loss: 3321251453.716115\n",
      "\n",
      "Iteration: 18) Accuracy train: 0.497859 - Accuracy test: 0.488665 - Loss: 3608504024.183042\n",
      "\n",
      "Iteration: 19) Accuracy train: 0.482872 - Accuracy test: 0.487154 - Loss: 13725499508.405146\n",
      "\n",
      "Iteration: 20) Accuracy train: 0.496599 - Accuracy test: 0.528967 - Loss: 17042386188.458263\n",
      "\n",
      "Iteration: 21) Accuracy train: 0.505919 - Accuracy test: 0.518892 - Loss: 1141411168.142721\n",
      "\n",
      "Iteration: 22) Accuracy train: 0.503401 - Accuracy test: 0.509320 - Loss: 7200634417.534714\n",
      "\n",
      "Iteration: 23) Accuracy train: 0.496977 - Accuracy test: 0.499244 - Loss: 5544067779.302958\n",
      "\n",
      "Iteration: 24) Accuracy train: 0.530982 - Accuracy test: 0.531486 - Loss: 6026475515.025896\n",
      "\n",
      "Iteration: 25) Accuracy train: 0.488791 - Accuracy test: 0.485642 - Loss: 7424106064.521799\n",
      "\n",
      "Iteration: 26) Accuracy train: 0.497985 - Accuracy test: 0.493199 - Loss: 125488648902.678909\n",
      "\n",
      "Iteration: 27) Accuracy train: 0.490176 - Accuracy test: 0.488665 - Loss: 5083780033173.383789\n",
      "\n",
      "Iteration: 28) Accuracy train: 0.517632 - Accuracy test: 0.526448 - Loss: 7423265826.543177\n",
      "\n",
      "Iteration: 29) Accuracy train: 0.504912 - Accuracy test: 0.522418 - Loss: 1114166143.724923\n",
      "\n",
      "Accuracy test, mean: 0.503224, min value: 0.476574, max value: 0.531486 \n",
      "\n",
      "Accuracy train, mean: 0.503237, min value: 0.473804, max value: 0.538035 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "\n",
    "# Just for study    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1588,127) and (18,) not aligned: 127 (dim 1) != 18 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-67e43ae3e98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_jet_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dropped_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maccuracy_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k, degree, m, **args)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# methods used to calculate weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w after\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/helpers.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# compute loss, gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# gradient w by descent update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/project1-ML/scripts/helpers.py\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;34m\"\"\"Compute the gradient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1588,127) and (18,) not aligned: 127 (dim 1) != 18 (dim 0)"
     ]
    }
   ],
   "source": [
    "# GRADIENT DESCEND \n",
    "# HEREEEE!\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "gamma = 0.01\n",
    "max_iterations = 500\n",
    "\n",
    "# CHECK SHAPES!!!!!!!!!!!!!!!!!!!!! and correct!\n",
    "k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "initial_w = np.zeros(features_dropped_0.shape[1])\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, gradient_descent, initial_w=initial_w, max_iters=max_iterations, gamma=gamma)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = []\n",
    "test_poly = build_poly(tx_median_test, degree)\n",
    "y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = [init_w]\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_jet_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
