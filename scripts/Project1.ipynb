{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import generate_4_sets_looking_on_jetnum, columns_contains_just_missing_values, columns_contains_same_value\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATAS LOADED!\n",
      "TEST DATAS LOADED!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=True)\n",
    "print(\"TRAIN DATAS LOADED!\")\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=True)\n",
    "print(\"TEST DATAS LOADED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean, median  or normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with mean for each feature\n",
    "# train set\n",
    "means = find_mean(tx)\n",
    "tx_replaced_by_mean = replace_missing_values(tx, means)\n",
    "\n",
    "# test set\n",
    "means_test = find_mean(tx_test)\n",
    "tx_replaced_by_mean_test = replace_missing_values(tx_test, means_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for each feature\n",
    "# train set\n",
    "medians = find_median(tx)\n",
    "tx_replaced_by_median = replace_missing_values(tx, medians)\n",
    "\n",
    "# test set\n",
    "medians_test = find_median(tx_test)\n",
    "tx_replaced_by_median_test = replace_missing_values(tx_test, medians_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 0 and before that normalize all values without considering missing values\n",
    "std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "tx_std_data_replaced_by_0 = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_jet_0, features_jet_1, features_jet_2, features_jet_3 = generate_4_sets_looking_on_jetnum(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 148.436   43.251  118.888 ... -999.    -999.       0.   ]\n",
      " [-999.      86.317   73.988 ... -999.    -999.       0.   ]\n",
      " [-999.      64.299   64.676 ... -999.    -999.       0.   ]\n",
      " ...\n",
      " [-999.      88.445   54.259 ... -999.    -999.       0.   ]\n",
      " [  81.153   28.748   63.335 ... -999.    -999.       0.   ]\n",
      " [-999.      78.589   76.993 ... -999.    -999.       0.   ]]\n",
      "[4, 5, 6, 12, 23, 24, 25, 26, 27, 28, 22]\n",
      "[4, 5, 6, 12, 26, 27, 28, 22]\n",
      "[22]\n",
      "[22]\n"
     ]
    }
   ],
   "source": [
    "# iterate to find which columns to drop\n",
    "columns_to_remove_0 = columns_contains_just_missing_values(features_jet_0[0])\n",
    "columns_to_remove_1 = columns_contains_just_missing_values(features_jet_1[0])\n",
    "columns_to_remove_2 = columns_contains_just_missing_values(features_jet_2[0])\n",
    "columns_to_remove_3 = columns_contains_just_missing_values(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28. And also we will drop feature 22 since it is the one of jet_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature 22 since it is the one of jet_num and it will contains the same value.\n",
    "columns_to_remove_0.append(22)\n",
    "columns_to_remove_1.append(22)\n",
    "columns_to_remove_2.append(22)\n",
    "columns_to_remove_3.append(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for constant values, if I feature contains all the same values it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[4, 5, 6, 12, 22, 26, 27, 28]\n",
      "[22]\n",
      "[22]\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove_0_b = columns_contains_same_value(features_jet_0[0])\n",
    "columns_to_remove_1_b = columns_contains_same_value(features_jet_1[0])\n",
    "columns_to_remove_2_b = columns_contains_same_value(features_jet_2[0])\n",
    "columns_to_remove_3_b = columns_contains_same_value(features_jet_3[0])\n",
    "print(columns_to_remove_0_b)\n",
    "print(columns_to_remove_1_b)\n",
    "print(columns_to_remove_2_b)\n",
    "print(columns_to_remove_3_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that as predicted we should removed feature 22. We have found also feature 29 to remove from column 0.\n",
    "Since before we have dropped columns full of -999 (same value) we can just remove these features from each set.\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> [22]\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns from subset    \n",
    "features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0_b, axis=1)\n",
    "features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1_b, axis=1)\n",
    "features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2_b, axis=1)\n",
    "features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "tx_dropped_columns = np.delete(tx, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 19\n",
    "degree = 7\n",
    "k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.804520 - Accuracy test: 0.799740 - Loss: 0.575760\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.800310 - Accuracy test: 0.802020 - Loss: 0.585639\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.806710 - Accuracy test: 0.808080 - Loss: 0.572250\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.804575 - Accuracy test: 0.800720 - Loss: 0.576161\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.803565 - Accuracy test: 0.804200 - Loss: 0.577485\n",
      "\n",
      "Accuracy test, mean: 0.802952, min value: 0.799740, max value: 0.808080 \n",
      "\n",
      "Accuracy train, mean: 0.803936, min value: 0.800310, max value: 0.806710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Just for study the behaviour\n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.805525 - Accuracy test: 0.801640 - Loss: 0.573839\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.804210 - Accuracy test: 0.807480 - Loss: 0.576331\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.808065 - Accuracy test: 0.809400 - Loss: 0.569957\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.805485 - Accuracy test: 0.801400 - Loss: 0.574242\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.804755 - Accuracy test: 0.805380 - Loss: 0.575564\n",
      "\n",
      "Accuracy test, mean: 0.805060, min value: 0.801400, max value: 0.809400 \n",
      "\n",
      "Accuracy train, mean: 0.805608, min value: 0.804210, max value: 0.808065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "# Just for study the behaviour    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by 0 after having normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_std_data_replaced_by_0, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "# Just for study    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "\n",
    "# Just for study    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.654965 - Accuracy test: 0.653340 - Loss: 2.902052\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.668780 - Accuracy test: 0.670180 - Loss: 125.230677\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.785245 - Accuracy test: 0.786400 - Loss: 0.622517\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.764410 - Accuracy test: 0.762780 - Loss: 0.677012\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.777095 - Accuracy test: 0.777480 - Loss: 0.644077\n",
      "\n",
      "Accuracy test, mean: 0.730036, min value: 0.653340, max value: 0.786400 \n",
      "\n",
      "Accuracy train, mean: 0.730099, min value: 0.654965, max value: 0.785245 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = []\n",
    "test_poly = build_poly(tx_median_test, degree)\n",
    "y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_dropped_0.shape)\n",
    "print(features_dropped_1.shape)\n",
    "print(features_dropped_2.shape)\n",
    "print(features_dropped_3.shape)\n",
    "\n",
    "print(columns_to_remove_0)\n",
    "print(columns_to_remove_1)\n",
    "print(columns_to_remove_2)\n",
    "print(columns_to_remove_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
