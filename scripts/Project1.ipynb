{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import generate_4_sets_looking_on_jetnum\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1. ...  1. -1. -1.]\n",
      "[[ 138.47    51.655   97.827 ...    1.24    -2.475  113.497]\n",
      " [ 160.937   68.768  103.235 ... -999.    -999.      46.226]\n",
      " [-999.     162.172  125.953 ... -999.    -999.      44.251]\n",
      " ...\n",
      " [ 105.457   60.526   75.839 ... -999.    -999.      41.992]\n",
      " [  94.951   19.362   68.812 ... -999.    -999.       0.   ]\n",
      " [-999.      72.756   70.831 ... -999.    -999.       0.   ]]\n",
      "[100000 100001 100002 ... 349997 349998 349999]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=False)\n",
    "print(y)\n",
    "print(tx)\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean and median  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = find_mean(tx)\n",
    "median_array = find_median(tx)\n",
    "tx_mean = replace_missing_values(tx, mean_array)\n",
    "tx_median = replace_missing_values(tx, median_array)\n",
    "\n",
    "std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "\n",
    "std_data = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))\n",
    "\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)\n",
    "mean_array_test = find_mean(tx_test)\n",
    "median_array_test = find_median(tx_test)\n",
    "tx_mean_test = replace_missing_values(tx_test, mean_array_test)\n",
    "tx_median_test = replace_missing_values(tx_test, median_array_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 19\n",
    "degree = 7\n",
    "k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEAN VALUE\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-336-5d5d97334229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_accuracy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maccuracy_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_accuracy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "print(\"RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEAN VALUE\\n\")\n",
    "\n",
    "# define lists to store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "y_test_predicted = []\n",
    "\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test, y_t_p = cross_validation(y, tx_mean, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    y_test_predicted.append(y_t_p)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "print(\"RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEDIAN VALUE\\n\")\n",
    "\n",
    "# define lists to store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_median, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUBMIT PREDICTION\n",
    "y_test_predicted = []\n",
    "\n",
    "test_poly = build_poly(tx_median_test, degree)\n",
    "\n",
    "y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "print(y_test_predicted.shape)\n",
    "print(y_test_predicted)\n",
    "print(ids_test.shape)\n",
    "\n",
    "create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEAN VALUE\\n\")\n",
    "\n",
    "# define lists to store the accuracy of training data and test data\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "\n",
    "    \n",
    "  \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "print(\"RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEDIAN VALUE\\n\")\n",
    "\n",
    "# define lists to store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "for lambda_ in lambdas:\n",
    "    accuracy_train_temp = []\n",
    "    accuracy_test_temp = []\n",
    "    losses_temp = []\n",
    "    for k in range(k_fold):\n",
    "        loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "        accuracy_train_temp.append(single_accuracy_train)\n",
    "        accuracy_test_temp.append(single_accuracy_test)\n",
    "        losses_temp.append(loss)\n",
    "    accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "    accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "    losses.append(np.mean(losses_temp))\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "print(\"RESULTS OBTAINED USING k=5 AND REPLACING MISSING VALUES WITH MEDIAN VALUE\\n\")\n",
    "\n",
    "# define lists to store the accuracy of training data and test data\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, std_data, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_jet_0, features_jet_1, features_jet_2, features_jet_3 = generate_4_sets_looking_on_jetnum(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate to find which columns to drop\n",
    "columns_to_remove_0 = []\n",
    "columns_to_remove_1 = []\n",
    "columns_to_remove_2 = []\n",
    "columns_to_remove_3 = []\n",
    "\n",
    "features_dropped = features_jet_0[0]\n",
    "for i in range (0, 30):\n",
    "    if(np.all(features_jet_0[0][:, i] == -999.)):\n",
    "        columns_to_remove_0.append(i)    \n",
    "    if(np.all(features_jet_1[0][:, i] == -999.)):\n",
    "        columns_to_remove_1.append(i) \n",
    "    if(np.all(features_jet_2[0][:, i] == -999.)):\n",
    "         columns_to_remove_2.append(i)\n",
    "    if(np.all(features_jet_3[0][:, i] == -999.)):\n",
    "         columns_to_remove_3.append(i) \n",
    "        \n",
    "features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0, axis=1)\n",
    "features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1, axis=1)\n",
    "features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2, axis=1)\n",
    "features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.654965 - Accuracy test: 0.653340 - Loss: 2.902052\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.668780 - Accuracy test: 0.670180 - Loss: 125.230677\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.785245 - Accuracy test: 0.786400 - Loss: 0.622517\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.764410 - Accuracy test: 0.762780 - Loss: 0.677012\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.777095 - Accuracy test: 0.777480 - Loss: 0.644077\n",
      "\n",
      "Accuracy test, mean: 0.730036, min value: 0.653340, max value: 0.786400 \n",
      "\n",
      "Accuracy train, mean: 0.730099, min value: 0.654965, max value: 0.785245 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "losses = []\n",
    "weights = []\n",
    "\n",
    "columns_to_remove = [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "tx_dropped = np.delete(tx, columns_to_remove, axis=1)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "    accuracy_train.append(single_accuracy_train)\n",
    "    accuracy_test.append(single_accuracy_test)\n",
    "    losses.append(loss)\n",
    "    weights.append(w)\n",
    "\n",
    "    \n",
    "n = len(accuracy_train)\n",
    "for i in range(n):\n",
    "    print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "mean_accuracy_test = np.mean(accuracy_test)\n",
    "min_accuracy_test = np.min(accuracy_test)\n",
    "max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "mean_accuracy_train = np.mean(accuracy_train)\n",
    "min_accuracy_train = np.min(accuracy_train)\n",
    "max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 23)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249993,)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249993,)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 20)\n",
      "(77544, 23)\n",
      "(50379, 30)\n",
      "(22164, 30)\n",
      "[4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
      "[4, 5, 6, 12, 26, 27, 28]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(features_dropped_0.shape)\n",
    "print(features_dropped_1.shape)\n",
    "print(features_dropped_2.shape)\n",
    "print(features_dropped_3.shape)\n",
    "\n",
    "print(columns_to_remove_0)\n",
    "print(columns_to_remove_1)\n",
    "print(columns_to_remove_2)\n",
    "print(columns_to_remove_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
