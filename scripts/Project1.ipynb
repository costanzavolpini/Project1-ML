{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import *\n",
    "from execute_code import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA LOADED!\n",
      "TEST DATA LOADED!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=True)\n",
    "print(\"TRAIN DATA LOADED!\")\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)\n",
    "print(\"TEST DATA LOADED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean, median  or normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with mean for each feature\n",
    "# # train set\n",
    "\n",
    "# means = find_mean(tx)\n",
    "# tx_replaced_by_mean = replace_missing_values(tx, means)\n",
    "\n",
    "# # test set\n",
    "# means_test = find_mean(tx_test)\n",
    "# tx_replaced_by_mean_test = replace_missing_values(tx_test, means_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for each feature\n",
    "# # train set\n",
    "# medians = find_median(tx)\n",
    "# tx_replaced_by_median = replace_missing_values(tx, medians)\n",
    "\n",
    "# # test set\n",
    "# medians_test = find_median(tx_test)\n",
    "# tx_replaced_by_median_test = replace_missing_values(tx_test, medians_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with 0 and before that normalize all values without considering missing values\n",
    "# std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "# tx_std_data_replaced_by_0 = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_jet_0, features_jet_1, features_jet_2, features_jet_3, y_jet_0, y_jet_1, y_jet_2, y_jet_3, ids_jet_0, ids_jet_1, ids_jet_2, ids_jet_3 = generate_4_sets_looking_on_jetnum(tx, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate to find which columns to drop\n",
    "# columns_to_remove_0 = columns_contains_just_missing_values(features_jet_0[0])\n",
    "# columns_to_remove_1 = columns_contains_just_missing_values(features_jet_1[0])\n",
    "# columns_to_remove_2 = columns_contains_just_missing_values(features_jet_2[0])\n",
    "# columns_to_remove_3 = columns_contains_just_missing_values(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28. And also we will drop feature 22 since it is the one of jet_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop feature 22 since it is the one of jet_num and it will contains the same value.\n",
    "# columns_to_remove_0.append(22)\n",
    "# columns_to_remove_1.append(22)\n",
    "# columns_to_remove_2.append(22)\n",
    "# columns_to_remove_3.append(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for constant values, if I feature contains all the same values it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove_0_b = columns_contains_same_value(features_jet_0[0])\n",
    "# columns_to_remove_1_b = columns_contains_same_value(features_jet_1[0])\n",
    "# columns_to_remove_2_b = columns_contains_same_value(features_jet_2[0])\n",
    "# columns_to_remove_3_b = columns_contains_same_value(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that as predicted we should removed feature 22. We have found also feature 29 to remove from column 0.\n",
    "Since before we have dropped columns full of -999 (same value) we can just remove these features from each set.\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> [22]\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove columns from subset    \n",
    "# features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0_b, axis=1)\n",
    "# features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1_b, axis=1)\n",
    "# features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2_b, axis=1)\n",
    "# features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "# tx_dropped_columns = np.delete(tx, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 19\n",
    "# degree = 7\n",
    "# k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "# k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.804520 - Accuracy test: 0.799740 - Loss: 0.575760\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.800310 - Accuracy test: 0.802020 - Loss: 0.585639\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.806710 - Accuracy test: 0.808080 - Loss: 0.572250\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.804575 - Accuracy test: 0.800720 - Loss: 0.576161\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.803565 - Accuracy test: 0.804200 - Loss: 0.577485\n",
      "\n",
      "Accuracy test, mean: 0.802952, min value: 0.799740, max value: 0.808080 \n",
      "\n",
      "Accuracy train, mean: 0.803936, min value: 0.800310, max value: 0.806710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "    \n",
    "# # Just for study the behaviour\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.805525 - Accuracy test: 0.801640 - Loss: 0.573839\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.804210 - Accuracy test: 0.807480 - Loss: 0.576331\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.808065 - Accuracy test: 0.809400 - Loss: 0.569957\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.805485 - Accuracy test: 0.801400 - Loss: 0.574242\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.804755 - Accuracy test: 0.805380 - Loss: 0.575564\n",
      "\n",
      "Accuracy test, mean: 0.805060, min value: 0.801400, max value: 0.809400 \n",
      "\n",
      "Accuracy train, mean: 0.805608, min value: 0.804210, max value: 0.808065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study the behaviour    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by 0 after having normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_std_data_replaced_by_0, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cross validation, division by jet_num with different ML implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test jet_num_0 dataset with:\n",
    "- **Least squares regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 <br/>\n",
    "    Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
    "- **Ridge regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.503224, min value: 0.476574, max value: 0.531486 <br/>\n",
    "    Accuracy train, mean: 0.503237, min value: 0.473804, max value: 0.538035 \n",
    "- **Linear regression using gradient descent**: <br/>\n",
    "- **Linear regression using stochastic gradient descent**:\n",
    "- **Logistic regression using gradient descent or SGD**:\n",
    "- **Regularized logistic regression using gradient descent or SGD**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.511335 - Accuracy test: 0.513854 - Loss: 417040.188757\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.773929 - Accuracy test: 0.795970 - Loss: 0.739157\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.529597 - Accuracy test: 0.511335 - Loss: 95905.419265\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.534635 - Accuracy test: 0.549118 - Loss: 1306.744284\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.580605 - Accuracy test: 0.546599 - Loss: 21577866.290756\n",
      "\n",
      "Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 \n",
      "\n",
      "Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    }
   ],
   "source": [
    "# # accuracy_train = []\n",
    "# # accuracy_test = []\n",
    "# # losses = []\n",
    "# # weights = []\n",
    "\n",
    "# # for k in range(k_fold):\n",
    "# #     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "# #     accuracy_train.append(single_accuracy_train)\n",
    "# #     accuracy_test.append(single_accuracy_test)\n",
    "# #     losses.append(loss)\n",
    "# #     weights.append(w)\n",
    "\n",
    "    \n",
    "# # n = len(accuracy_train)\n",
    "# # for i in range(n):\n",
    "# #     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# # mean_accuracy_test = np.mean(accuracy_test)\n",
    "# # min_accuracy_test = np.min(accuracy_test)\n",
    "# # max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# # mean_accuracy_train = np.mean(accuracy_train)\n",
    "# # min_accuracy_train = np.min(accuracy_train)\n",
    "# # max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# # print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# # print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "# #LEAST SQUARE\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RIDGE REGRESSION\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/helpers.py:5: RuntimeWarning: overflow encountered in square\n",
      "  return 1/(len(y)) * np.sum(e**2)\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Accuracy test, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n",
      "Accuracy train, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # GRADIENT DESCEND \n",
    "# # HEREEEE! NOT WORK!\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "# gamma = 0.01\n",
    "# max_iterations = 500\n",
    "\n",
    "# # CHECK SHAPES!!!!!!!!!!!!!!!!!!!!! and correct!\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# initial_w = np.zeros(features_dropped_0.shape[1])\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, gradient_descent, initial_w=initial_w, max_iters=max_iterations, gamma=gamma)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28075458,  0.03965436,  0.40651625, ...,  0.61755292,\n",
       "        -1.30266251,  0.39818214],\n",
       "       [ 1.63061547,  0.63344061,  1.05925506, ...,  0.        ,\n",
       "         0.        , -0.23179611],\n",
       "       [-0.51771811, -0.64151886, -0.37784339, ...,  0.        ,\n",
       "         0.        , -0.10829837],\n",
       "       ...,\n",
       "       [ 0.34569571, -1.22366112,  0.43998942, ...,  0.        ,\n",
       "         0.        ,  0.23416077],\n",
       "       [-0.72942585, -0.11217409, -0.50441304, ...,  0.        ,\n",
       "         0.        , -0.41106251],\n",
       "       [ 0.13958259, -1.31829705, -0.3187276 , ...,  0.        ,\n",
       "         0.        , -0.22539659]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test_predicted = []\n",
    "# test_poly = build_poly(tx_median_test, degree)\n",
    "# y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "# create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 397), (1985,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build_k_indices(y_0, 5, 19).shape, y_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test my new file!!!!!!!!!!! DA QUI:\n",
    "y_test = np.zeros(tx_test.shape[0])\n",
    "# tx_med = replace_set_median(tx)\n",
    "tx_out = tx\n",
    "# tx_out = outlier_removal(tx_med, 95, 1, per_top = True, per_bot = True)\n",
    "tx_0, tx_1, tx_2, tx_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 = divide_dataset_looking_jetnum_and_remove_features(y, tx_out, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_0 = tx_0.copy()\n",
    "tx_1 = tx_1.copy()\n",
    "tx_2 = tx_2.copy()\n",
    "tx_3 = tx_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < 1e-8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.535516, min value: 0.355164, max value: 0.675063 \n",
      "\n",
      "Accuracy train, mean: 0.768892, min value: 0.758186, max value: 0.777708 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.706297, min value: 0.586902, max value: 0.750630 \n",
      "\n",
      "Accuracy train, mean: 0.765869, min value: 0.760076, max value: 0.769521 \n",
      "\n",
      "3. GRADIENT DESCENT\n",
      "\n",
      "Accuracy test, mean: 0.562720, min value: 0.531486, max value: 0.584383 \n",
      "\n",
      "Accuracy train, mean: 0.572418, min value: 0.557305, max value: 0.595718 \n",
      "\n",
      "4. STOCHASTIC GRADIENT\n",
      "\n",
      "Accuracy test, mean: 0.591436, min value: 0.536524, max value: 0.637280 \n",
      "\n",
      "Accuracy train, mean: 0.583249, min value: 0.557305, max value: 0.602015 \n",
      "\n",
      "5. LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.816121, min value: 0.801008, max value: 0.826196 \n",
      "\n",
      "Accuracy train, mean: 0.808312, min value: 0.785894, max value: 0.824937 \n",
      "\n",
      "6. REGULARIZED LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.584887, min value: 0.559194, max value: 0.619647 \n",
      "\n",
      "Accuracy train, mean: 0.595844, min value: 0.557305, max value: 0.655542 \n",
      "\n",
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.816121\n"
     ]
    }
   ],
   "source": [
    "acc0, m0, w0 = execute_all_methods(y_0, tx_0, ids_0, True, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", m0)\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < 1e-8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.500649, min value: 0.376623, max value: 0.600649 \n",
      "\n",
      "Accuracy train, mean: 0.778571, min value: 0.774351, max value: 0.790584 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.704545, min value: 0.672078, max value: 0.769481 \n",
      "\n",
      "Accuracy train, mean: 0.750812, min value: 0.741883, max value: 0.760552 \n",
      "\n",
      "3. GRADIENT DESCENT\n",
      "\n",
      "Accuracy test, mean: 0.538961, min value: 0.509740, max value: 0.561688 \n",
      "\n",
      "Accuracy train, mean: 0.547240, min value: 0.519481, max value: 0.564935 \n",
      "\n",
      "4. STOCHASTIC GRADIENT\n",
      "\n",
      "Accuracy test, mean: 0.535714, min value: 0.474026, max value: 0.613636 \n",
      "\n",
      "Accuracy train, mean: 0.547890, min value: 0.508929, max value: 0.585227 \n",
      "\n",
      "5. LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.734416, min value: 0.720779, max value: 0.762987 \n",
      "\n",
      "Accuracy train, mean: 0.793019, min value: 0.774351, max value: 0.806006 \n",
      "\n",
      "6. REGULARIZED LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.553896, min value: 0.516234, max value: 0.603896 \n",
      "\n",
      "Accuracy train, mean: 0.550649, min value: 0.513799, max value: 0.592532 \n",
      "\n",
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.734416\n"
     ]
    }
   ],
   "source": [
    "acc1, m1, w1 = execute_all_methods(y_1, tx_1, ids_1, True, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", m1)\n",
    "print(\"with accuracy %f\" %(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < 1e-8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.475962, min value: 0.331731, max value: 0.528846 \n",
      "\n",
      "Accuracy train, mean: 0.875721, min value: 0.856971, max value: 0.887019 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.725962, min value: 0.663462, max value: 0.759615 \n",
      "\n",
      "Accuracy train, mean: 0.855048, min value: 0.834135, max value: 0.864183 \n",
      "\n",
      "3. GRADIENT DESCENT\n",
      "\n",
      "Accuracy test, mean: 0.544231, min value: 0.495192, max value: 0.586538 \n",
      "\n",
      "Accuracy train, mean: 0.564904, min value: 0.531250, max value: 0.587740 \n",
      "\n",
      "4. STOCHASTIC GRADIENT\n",
      "\n",
      "Accuracy test, mean: 0.593269, min value: 0.528846, max value: 0.629808 \n",
      "\n",
      "Accuracy train, mean: 0.590144, min value: 0.570913, max value: 0.623798 \n",
      "\n",
      "5. LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.758654, min value: 0.716346, max value: 0.826923 \n",
      "\n",
      "Accuracy train, mean: 0.846875, min value: 0.835337, max value: 0.856971 \n",
      "\n",
      "6. REGULARIZED LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.542308, min value: 0.475962, max value: 0.576923 \n",
      "\n",
      "Accuracy train, mean: 0.555288, min value: 0.516827, max value: 0.588942 \n",
      "\n",
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.758654\n"
     ]
    }
   ],
   "source": [
    "acc2, m2, w2 = execute_all_methods(y_2, tx_2, ids_2, True, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", m2)\n",
    "print(\"with accuracy %f\" %(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < 1e-8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.502326, min value: 0.372093, max value: 0.581395 \n",
      "\n",
      "Accuracy train, mean: 0.883721, min value: 0.860465, max value: 0.895349 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.590698, min value: 0.511628, max value: 0.639535 \n",
      "\n",
      "Accuracy train, mean: 0.815116, min value: 0.802326, max value: 0.828488 \n",
      "\n",
      "3. GRADIENT DESCENT\n",
      "\n",
      "Accuracy test, mean: 0.520930, min value: 0.488372, max value: 0.558140 \n",
      "\n",
      "Accuracy train, mean: 0.554651, min value: 0.517442, max value: 0.566860 \n",
      "\n",
      "4. STOCHASTIC GRADIENT\n",
      "\n",
      "Accuracy test, mean: 0.560465, min value: 0.546512, max value: 0.569767 \n",
      "\n",
      "Accuracy train, mean: 0.550581, min value: 0.529070, max value: 0.569767 \n",
      "\n",
      "5. LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.686047, min value: 0.651163, max value: 0.744186 \n",
      "\n",
      "Accuracy train, mean: 0.851744, min value: 0.834302, max value: 0.869186 \n",
      "\n",
      "6. REGULARIZED LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.574419, min value: 0.523256, max value: 0.639535 \n",
      "\n",
      "Accuracy train, mean: 0.526163, min value: 0.488372, max value: 0.552326 \n",
      "\n",
      "Selected method  LOGISTIC REGRESSION\n",
      "with accuracy 0.686047\n"
     ]
    }
   ],
   "source": [
    "acc3, m3, w3 = execute_all_methods(y_3, tx_3, ids_3, True, lambda_=0.0001, initial_w=None, max_iters=1000, gamma=1e-3)\n",
    "print(\"Selected method \", m3)\n",
    "print(\"with accuracy %f\" %(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_0_t, tx_1_t, tx_2_t, tx_3_t, _, _, _, _, ids_0_t, ids_1_t, ids_2_t, ids_3_t = divide_dataset_looking_jetnum_and_remove_features(y_test, tx_test, ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.50000e+05 -1.00000e+00]\n",
      " [ 3.50002e+05  1.00000e+00]\n",
      " [ 3.50003e+05  1.00000e+00]\n",
      " ...\n",
      " [ 9.18232e+05 -1.00000e+00]\n",
      " [ 9.18235e+05  1.00000e+00]\n",
      " [ 9.18237e+05 -1.00000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., ...,  1.,  1., -1.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_submission(tx_0_t, tx_1_t, tx_2_t, tx_3_t, ids_0_t, ids_1_t, ids_2_t, ids_3_t, w0, w1, w2, w3, \"submission-28-10-to-submit\", 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 204, 204, 127)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w1), len(w2), len(w3), len(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final = np.concatenate((w0, w1, w2, w3))\n",
    "ids_final = np.concatenate((ids_0, ids_1, ids_2, ids_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0030e+05 -1.0000e+00]\n",
      " [ 1.0035e+05 -1.0000e+00]\n",
      " [ 1.0050e+05 -1.0000e+00]\n",
      " ...\n",
      " [ 3.4945e+05 -1.0000e+00]\n",
      " [ 3.4955e+05  1.0000e+00]\n",
      " [ 3.4970e+05 -1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "preddd = generate_submission(tx_0, tx_1, tx_2, tx_3, ids_0, ids_1, ids_2, ids_3, w0, w1, w2, w3, \"submission-28-10-to-submit\", 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preddd == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819647355163728"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted0 = []\n",
    "    test_poly0 = build_poly(tx_0, 7)\n",
    "    test_poly0 = replace_set_normalize(test_poly0)\n",
    "    y_test_predicted0 = predict_labels(w0, test_poly0)\n",
    "np.sum(y_test_predicted0 == y_0)/len(y_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766233766233767"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted1 = []\n",
    "    test_poly1 = build_poly(tx_1, 7)\n",
    "    test_poly1 = replace_set_normalize(test_poly1)\n",
    "    y_test_predicted1 = predict_labels(w1, test_poly1)\n",
    "np.sum(y_test_predicted1 == y_1)/len(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293384467881112"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted2 = []\n",
    "    test_poly2 = build_poly(tx_2, 7)\n",
    "    test_poly2 = replace_set_normalize(test_poly2)\n",
    "    y_test_predicted2 = predict_labels(w2, test_poly2)\n",
    "np.sum(y_test_predicted2 == y_2)/len(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893518518518519"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y_test_predicted3 = []\n",
    "    test_poly3 = build_poly(tx_3, 7)\n",
    "    test_poly3 = replace_set_normalize(test_poly3)\n",
    "    y_test_predicted3 = predict_labels(w3, test_poly3)\n",
    "np.sum(y_test_predicted3 == y_3)/len(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
