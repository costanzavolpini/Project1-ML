{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 \n",
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from split_jet_num import *\n",
    "from execute_code import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATAS LOADED!\n",
      "TEST DATAS LOADED!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y: class labels\n",
    "    tx: features\n",
    "    ids: event ids \"\"\"\n",
    "y, tx, ids = load_csv_data(\"datas/train.csv\", sub_sample=True)\n",
    "print(\"TRAIN DATAS LOADED!\")\n",
    "\n",
    "no_y, tx_test, ids_test = load_csv_data(\"datas/test.csv\", sub_sample=False)\n",
    "print(\"TEST DATAS LOADED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "### Replace missing values with mean, median  or normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with mean for each feature\n",
    "# # train set\n",
    "\n",
    "# means = find_mean(tx)\n",
    "# tx_replaced_by_mean = replace_missing_values(tx, means)\n",
    "\n",
    "# # test set\n",
    "# means_test = find_mean(tx_test)\n",
    "# tx_replaced_by_mean_test = replace_missing_values(tx_test, means_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for each feature\n",
    "# # train set\n",
    "# medians = find_median(tx)\n",
    "# tx_replaced_by_median = replace_missing_values(tx, medians)\n",
    "\n",
    "# # test set\n",
    "# medians_test = find_median(tx_test)\n",
    "# tx_replaced_by_median_test = replace_missing_values(tx_test, medians_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace missing values with 0 and before that normalize all values without considering missing values\n",
    "# std_data_tx_with_mask = standardize(clean_array(tx))\n",
    "# tx_std_data_replaced_by_0 = replace_missing_values(std_data_tx_with_mask, np.full((30, 1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the dataset looking on jet num\n",
    "If PRI_jet_num is zero or one then some features are -999.\n",
    "Divide dataset in 4 looking on jet_num 0, 1, 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_jet_0, features_jet_1, features_jet_2, features_jet_3, y_jet_0, y_jet_1, y_jet_2, y_jet_3, ids_jet_0, ids_jet_1, ids_jet_2, ids_jet_3 = generate_4_sets_looking_on_jetnum(tx, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set look how many missing values there are.. in order to detect how many features we want to drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate to find which columns to drop\n",
    "# columns_to_remove_0 = columns_contains_just_missing_values(features_jet_0[0])\n",
    "# columns_to_remove_1 = columns_contains_just_missing_values(features_jet_1[0])\n",
    "# columns_to_remove_2 = columns_contains_just_missing_values(features_jet_2[0])\n",
    "# columns_to_remove_3 = columns_contains_just_missing_values(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that we don't need to remove any features when jet num is 2 and 3. \n",
    "\n",
    "\n",
    "Infact: \n",
    "\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> []\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> []\n",
    "\n",
    "\n",
    "We will drop features: 4, 5, 6, 12, 26, 27 and 28. And also we will drop feature 22 since it is the one of jet_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop feature 22 since it is the one of jet_num and it will contains the same value.\n",
    "# columns_to_remove_0.append(22)\n",
    "# columns_to_remove_1.append(22)\n",
    "# columns_to_remove_2.append(22)\n",
    "# columns_to_remove_3.append(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for constant values, if I feature contains all the same values it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove_0_b = columns_contains_same_value(features_jet_0[0])\n",
    "# columns_to_remove_1_b = columns_contains_same_value(features_jet_1[0])\n",
    "# columns_to_remove_2_b = columns_contains_same_value(features_jet_2[0])\n",
    "# columns_to_remove_3_b = columns_contains_same_value(features_jet_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that as predicted we should removed feature 22. We have found also feature 29 to remove from column 0.\n",
    "Since before we have dropped columns full of -999 (same value) we can just remove these features from each set.\n",
    "\n",
    "JET_NUM = 0 -> [4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "\n",
    "JET_NUM = 1 -> [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "\n",
    "JET_NUM = 2 -> [22]\n",
    "\n",
    "\n",
    "JET_NUM = 3 -> [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove columns from subset    \n",
    "# features_dropped_0 = np.delete(features_jet_0[0], columns_to_remove_0_b, axis=1)\n",
    "# features_dropped_1 = np.delete(features_jet_1[0], columns_to_remove_1_b, axis=1)\n",
    "# features_dropped_2 = np.delete(features_jet_2[0], columns_to_remove_2_b, axis=1)\n",
    "# features_dropped_3 = np.delete(features_jet_3[0], columns_to_remove_3_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = [4, 5, 6, 12, 22, 26, 27, 28]\n",
    "\n",
    "# tx_dropped_columns = np.delete(tx, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "K-fold cross-validation: original sample randomly partitioned into k equal sized subsamples.\n",
    "Repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 19\n",
    "# degree = 7\n",
    "# k_fold = 5\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30) #just for ridge regression\n",
    "\n",
    "# split data in k fold\n",
    "# k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML Methods\n",
    "### Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.804520 - Accuracy test: 0.799740 - Loss: 0.575760\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.800310 - Accuracy test: 0.802020 - Loss: 0.585639\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.806710 - Accuracy test: 0.808080 - Loss: 0.572250\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.804575 - Accuracy test: 0.800720 - Loss: 0.576161\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.803565 - Accuracy test: 0.804200 - Loss: 0.577485\n",
      "\n",
      "Accuracy test, mean: 0.802952, min value: 0.799740, max value: 0.808080 \n",
      "\n",
      "Accuracy train, mean: 0.803936, min value: 0.800310, max value: 0.806710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "    \n",
    "# # Just for study the behaviour\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.805525 - Accuracy test: 0.801640 - Loss: 0.573839\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.804210 - Accuracy test: 0.807480 - Loss: 0.576331\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.808065 - Accuracy test: 0.809400 - Loss: 0.569957\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.805485 - Accuracy test: 0.801400 - Loss: 0.574242\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.804755 - Accuracy test: 0.805380 - Loss: 0.575564\n",
      "\n",
      "Accuracy test, mean: 0.805060, min value: 0.801400, max value: 0.809400 \n",
      "\n",
      "Accuracy train, mean: 0.805608, min value: 0.804210, max value: 0.808065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # store the accuracy of training data and test data\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study the behaviour    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by 0 after having normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_std_data_replaced_by_0, k_indices, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_mean, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results obtained using k = 5 and replacing missing value by median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_replaced_by_median, k_indices, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cross validation, division by jet_num with different ML implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test jet_num_0 dataset with:\n",
    "- **Least squares regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 <br/>\n",
    "    Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
    "- **Ridge regression using normal equations**: <br/>\n",
    "    Accuracy test, mean: 0.503224, min value: 0.476574, max value: 0.531486 <br/>\n",
    "    Accuracy train, mean: 0.503237, min value: 0.473804, max value: 0.538035 \n",
    "- **Linear regression using gradient descent**: <br/>\n",
    "- **Linear regression using stochastic gradient descent**:\n",
    "- **Logistic regression using gradient descent or SGD**:\n",
    "- **Regularized logistic regression using gradient descent or SGD**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.511335 - Accuracy test: 0.513854 - Loss: 417040.188757\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.773929 - Accuracy test: 0.795970 - Loss: 0.739157\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.529597 - Accuracy test: 0.511335 - Loss: 95905.419265\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.534635 - Accuracy test: 0.549118 - Loss: 1306.744284\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.580605 - Accuracy test: 0.546599 - Loss: 21577866.290756\n",
      "\n",
      "Accuracy test, mean: 0.583375, min value: 0.511335, max value: 0.795970 \n",
      "\n",
      "Accuracy train, mean: 0.586020, min value: 0.511335, max value: 0.773929 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    }
   ],
   "source": [
    "# # accuracy_train = []\n",
    "# # accuracy_test = []\n",
    "# # losses = []\n",
    "# # weights = []\n",
    "\n",
    "# # for k in range(k_fold):\n",
    "# #     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y, tx_dropped, k_indices, k, degree, least_squares)\n",
    "# #     accuracy_train.append(single_accuracy_train)\n",
    "# #     accuracy_test.append(single_accuracy_test)\n",
    "# #     losses.append(loss)\n",
    "# #     weights.append(w)\n",
    "\n",
    "    \n",
    "# # n = len(accuracy_train)\n",
    "# # for i in range(n):\n",
    "# #     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# # mean_accuracy_test = np.mean(accuracy_test)\n",
    "# # min_accuracy_test = np.min(accuracy_test)\n",
    "# # max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# # mean_accuracy_train = np.mean(accuracy_train)\n",
    "# # min_accuracy_train = np.min(accuracy_train)\n",
    "# # max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# # print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# # print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n",
    "\n",
    "# #LEAST SQUARE\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, least_squares)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RIDGE REGRESSION\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "\n",
    "# for lambda_ in lambdas:\n",
    "#     accuracy_train_temp = []\n",
    "#     accuracy_test_temp = []\n",
    "#     losses_temp = []\n",
    "#     for k in range(k_fold):\n",
    "#         loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, ridge_regression, lambda_=lambda_)\n",
    "#         accuracy_train_temp.append(single_accuracy_train)\n",
    "#         accuracy_test_temp.append(single_accuracy_test)\n",
    "#         losses_temp.append(loss)\n",
    "#     accuracy_train.append(np.mean(accuracy_train_temp))\n",
    "#     accuracy_test.append(np.mean(accuracy_test_temp))\n",
    "#     losses.append(np.mean(losses_temp))\n",
    "\n",
    "# # Just for study    \n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/helpers.py:5: RuntimeWarning: overflow encountered in square\n",
      "  return 1/(len(y)) * np.sum(e**2)\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 1) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 2) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 3) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Iteration: 4) Accuracy train: 0.000000 - Accuracy test: 0.000000 - Loss: nan\n",
      "\n",
      "Accuracy test, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n",
      "Accuracy train, mean: 0.000000, min value: 0.000000, max value: 0.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # GRADIENT DESCEND \n",
    "# # HEREEEE! NOT WORK!\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# losses = []\n",
    "# weights = []\n",
    "# gamma = 0.01\n",
    "# max_iterations = 500\n",
    "\n",
    "# # CHECK SHAPES!!!!!!!!!!!!!!!!!!!!! and correct!\n",
    "# k_indices_0 = build_k_indices(y_jet_0, k_fold, seed)\n",
    "\n",
    "# initial_w = np.zeros(features_dropped_0.shape[1])\n",
    "\n",
    "# for k in range(k_fold):\n",
    "#     loss, w, single_accuracy_train, single_accuracy_test = cross_validation(y_jet_0, features_dropped_0, k_indices_0, k, degree, gradient_descent, initial_w=initial_w, max_iters=max_iterations, gamma=gamma)\n",
    "#     accuracy_train.append(single_accuracy_train)\n",
    "#     accuracy_test.append(single_accuracy_test)\n",
    "#     losses.append(loss)\n",
    "#     weights.append(w)\n",
    "\n",
    "# n = len(accuracy_train)\n",
    "# for i in range(n):\n",
    "#     print(\"Iteration: %d) Accuracy train: %f - Accuracy test: %f - Loss: %f\\n\" % (i, accuracy_train[i], accuracy_test[i], losses[i]))\n",
    "\n",
    "# mean_accuracy_test = np.mean(accuracy_test)\n",
    "# min_accuracy_test = np.min(accuracy_test)\n",
    "# max_accuracy_test = np.max(accuracy_test)\n",
    "\n",
    "# mean_accuracy_train = np.mean(accuracy_train)\n",
    "# min_accuracy_train = np.min(accuracy_train)\n",
    "# max_accuracy_train = np.max(accuracy_train)\n",
    "\n",
    "# print(\"Accuracy test, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_test, min_accuracy_test, max_accuracy_test))\n",
    "# print(\"Accuracy train, mean: %f, min value: %f, max value: %f \\n\" %(mean_accuracy_train, min_accuracy_train, max_accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28075458,  0.03965436,  0.40651625, ...,  0.61755292,\n",
       "        -1.30266251,  0.39818214],\n",
       "       [ 1.63061547,  0.63344061,  1.05925506, ...,  0.        ,\n",
       "         0.        , -0.23179611],\n",
       "       [-0.51771811, -0.64151886, -0.37784339, ...,  0.        ,\n",
       "         0.        , -0.10829837],\n",
       "       ...,\n",
       "       [ 0.34569571, -1.22366112,  0.43998942, ...,  0.        ,\n",
       "         0.        ,  0.23416077],\n",
       "       [-0.72942585, -0.11217409, -0.50441304, ...,  0.        ,\n",
       "         0.        , -0.41106251],\n",
       "       [ 0.13958259, -1.31829705, -0.3187276 , ...,  0.        ,\n",
       "         0.        , -0.22539659]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test_predicted = []\n",
    "# test_poly = build_poly(tx_median_test, degree)\n",
    "# y_test_predicted = predict_labels(weights[0], test_poly)\n",
    "# create_csv_submission(ids_test, y_test_predicted, \"submission-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 397), (1985,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_k_indices(y_0, 5, 19).shape, y_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "# Test my new file!!!!!!!!!!! DA QUI:\n",
    "y_test = np.zeros(tx_test.shape[0])\n",
    "tx_drop, tx_0, tx_1, tx_2, tx_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 = divide_dataset_looking_jetnum_and_remove_features(y, tx, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx_0, tx_1, tx_2, tx_3\n",
    "tx_0 = replace_set_normalize(tx_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:53: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.535516, min value: 0.355164, max value: 0.675063 \n",
      "\n",
      "Accuracy train, mean: 0.768892, min value: 0.758186, max value: 0.777708 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.706297, min value: 0.586902, max value: 0.750630 \n",
      "\n",
      "Accuracy train, mean: 0.765869, min value: 0.760076, max value: 0.769521 \n",
      "\n",
      "3. GRADIENT DESCENT\n",
      "\n",
      "Accuracy test, mean: 0.547607, min value: 0.518892, max value: 0.574307 \n",
      "\n",
      "Accuracy train, mean: 0.547607, min value: 0.531486, max value: 0.571159 \n",
      "\n",
      "4. STOCHASTIC GRADIENT\n",
      "\n",
      "Accuracy test, mean: 0.506297, min value: 0.460957, max value: 0.564232 \n",
      "\n",
      "Accuracy train, mean: 0.526071, min value: 0.472292, max value: 0.574937 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costanzavolpini/Git/project1-ML/scripts/helpers.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "  def calculate_loss_sigmoid(y, tx, w):\n",
      "/Users/costanzavolpini/Git/project1-ML/scripts/implementations.py:82: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  losses.append(loss)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.136524, min value: 0.118388, max value: 0.146096 \n",
      "\n",
      "Accuracy train, mean: 0.156297, min value: 0.146725, max value: 0.164358 \n",
      "\n",
      "6. REGULARIZED LOGISTIC REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.125441, min value: 0.098237, max value: 0.156171 \n",
      "\n",
      "Accuracy train, mean: 0.137028, min value: 0.129723, max value: 0.142317 \n",
      "\n",
      "Selected method  1. LEAST SQUARE\n",
      "with accuracy 0.768892\n"
     ]
    }
   ],
   "source": [
    "acc0, m0, w0 = execute_all_methods(y_0, tx_0, ids_0, True, lambda_=0.0001, initial_w=None, max_iters=500, gamma=1e-3)\n",
    "print(\"Selected method \", m0)\n",
    "print(\"with accuracy %f\" %(acc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02399589,  0.38276306, -0.33524168, -0.13780897, -0.03762188,\n",
       "       -0.60635885, -0.96950129,  0.6882121 ,  0.14546427,  0.3228853 ])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(10)*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.792855, min value: 0.786046, max value: 0.797201 \n",
      "\n",
      "Accuracy train, mean: 0.793813, min value: 0.792123, max value: 0.796653 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.792443, min value: 0.785788, max value: 0.796299 \n",
      "\n",
      "Accuracy train, mean: 0.793439, min value: 0.791446, max value: 0.796202 \n",
      "\n",
      "Selected method  1. LEAST SQUARE\n",
      "with accuracy 0.793813\n"
     ]
    }
   ],
   "source": [
    "acc1, m1, w1 = execute_all_methods(y_1, tx_1, ids_1, True, lambda_=0.0001)\n",
    "print(\"Selected method \", m1)\n",
    "print(\"with accuracy %f\" %(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.820387, min value: 0.817171, max value: 0.826402 \n",
      "\n",
      "Accuracy train, mean: 0.822462, min value: 0.821092, max value: 0.823251 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.820169, min value: 0.817767, max value: 0.825310 \n",
      "\n",
      "Accuracy train, mean: 0.822521, min value: 0.820695, max value: 0.823400 \n",
      "\n",
      "Selected method  2. RIDGE REGRESSION\n",
      "with accuracy 0.822521\n"
     ]
    }
   ],
   "source": [
    "acc2, m2, w2 = execute_all_methods(y_2, tx_2, ids_2, True, lambda_=0.0001)\n",
    "print(\"Selected method \", m2)\n",
    "print(\"with accuracy %f\" %(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LEAST SQUARE\n",
      "\n",
      "Accuracy test, mean: 0.810469, min value: 0.806182, max value: 0.815659 \n",
      "\n",
      "Accuracy train, mean: 0.816697, min value: 0.816336, max value: 0.817125 \n",
      "\n",
      "2. RIDGE REGRESSION\n",
      "\n",
      "Accuracy test, mean: 0.810785, min value: 0.805957, max value: 0.814079 \n",
      "\n",
      "Accuracy train, mean: 0.815783, min value: 0.815208, max value: 0.816279 \n",
      "\n",
      "Selected method  1. LEAST SQUARE\n",
      "with accuracy 0.816697\n"
     ]
    }
   ],
   "source": [
    "acc3, m3, w3 = execute_all_methods(y_3, tx_3, ids_3, True, lambda_=0.0001)\n",
    "print(\"Selected method \", m3)\n",
    "print(\"with accuracy %f\" %(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tx_0_t, tx_1_t, tx_2_t, tx_3_t, _, _, _, _, ids_0_t, ids_1_t, ids_2_t, ids_3_t = divide_dataset_looking_jetnum_and_remove_features(y_test, tx_test, ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(tx, tx_0_t, tx_1_t, tx_2_t, tx_3_t, ids_0_t, ids_1_t, ids_2_t, ids_3_t, w0, w1, w2, w3, \"submission-27-10\", 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
